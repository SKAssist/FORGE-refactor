"""
@file llama_agent.py
@description Optional Python backend for running local LLaMA models via llama.cpp or requests to Ollama.
Used for complex prompt templating or refactor planning when not handled in JS/TS.

@usedBy
- VSCode extension via subprocess (e.g., from extension.ts or node child_process)
"""
